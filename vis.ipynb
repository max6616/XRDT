{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cccf4a51",
   "metadata": {},
   "source": [
    "# Point Transformer V3 编解码与结果可视化\n",
    "\n",
    "这个 Notebook 用于加载一个基于 `PointTransformerV3` 训练好的 `MillerIndexerV3` 模型和一个衍射数据样本，然后在一个可交互的3D图表中进行可视化。\n",
    "\n",
    "**核心改动:**\n",
    "本脚本使用 **PyTorch Hooks** 来捕获模型中间层的输出，以适应 `PointTransformerV3` 的模块化设计，无需修改模型源代码即可实现对编码器和解码器各个阶段点云变化的追踪。\n",
    "\n",
    "**可视化内容:**\n",
    "1.  **编解码过程**: 查看在Encoder和Decoder各个阶段的点云下采样和上采样过程。\n",
    "2.  **米勒指数 (颜色)**: 以点的颜色表示hkl值，点的大小表示衍射强度。\n",
    "3.  **米勒指数 (方向)**: 以从点出发的矢量线段表示hkl值的方向，线段的颜色表示衍射强度。hkl为(0,0,0)的点将显示为灰色圆点。\n",
    "\n",
    "**步骤:**\n",
    "1.  **安装依赖**: 确保 `pointcept` 库已安装 (`pip install pointcept`).\n",
    "2.  **配置路径**: 在第二个代码单元中，设置好模型（`.pth`）和数据（`.jsonl`）的正确路径。\n",
    "3.  **运行所有单元**: 点击菜单栏的 `Cell` > `Run All`。\n",
    "4.  **交互查看**: 在最后的图表输出中，使用下拉菜单选择不同的模式进行查看。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1efa12b",
   "metadata": {},
   "source": [
    "### 1. 设置和导入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e51622",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from collections import OrderedDict\n",
    "\n",
    "# 确保这些模块可以被导入\n",
    "# 注意：模型已更新为 MillerIndexerV3\n",
    "from modelv3 import MillerIndexerV3 as MillerIndexer\n",
    "# 确保 pointcept 库已安装: pip install pointcept\n",
    "try:\n",
    "    from pointcept.models.utils.structure import Point\n",
    "except ImportError:\n",
    "    print(\"错误: 未找到 'pointcept' 库。请运行 'pip install pointcept' 进行安装。\")\n",
    "    raise\n",
    "\n",
    "# MODEL_PATH = '/root/autodl-tmp/tf-logs/xrdbert_pt/pt_v3_20250728_121347/best_model.pth' # 示例路径，请修改\n",
    "MODEL_PATH = 'pretrain/best_model.pth' # bigger\n",
    "num_classes = 11\n",
    "DATA_FILE = '/media/max/Data/datasets/mp_random_150k_v3_canonical/test/test_000004.jsonl' # 示例路径，请修改 # 13\n",
    "\n",
    "VIS_MASKING_RATIO = 1.0\n",
    "\n",
    "# -------------------\n",
    "\n",
    "def collate_fn_offset(batch):\n",
    "    \"\"\"一个简单的 collate_fn 示例，用于处理数据\"\"\"\n",
    "    coords, feats, labels = [], [], []\n",
    "    for i, (p, l) in enumerate(batch):\n",
    "        coords.append(torch.cat([torch.full((p.shape[0], 1), i), p], dim=1))\n",
    "        feats.append(p[:, :]) # 假设强度是第4列及之后\n",
    "        labels.append(l)\n",
    "    coords = torch.cat(coords, dim=0)\n",
    "    feats = torch.cat(feats, dim=0)\n",
    "    labels = torch.cat(labels, dim=0)\n",
    "    # 从 coords 中提取 p 和 o\n",
    "    p_out = coords[:, 1:] # 坐标 (x,y,z)\n",
    "    offsets = torch.tensor([b[0].shape[0] for b in batch], dtype=torch.long).cumsum(0)\n",
    "    return p_out, feats, labels, offsets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab808f47",
   "metadata": {},
   "source": [
    "### 2. 加载模型和数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6fe1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"--> 正在加载模型: {MODEL_PATH}\")\n",
    "in_channels = 4\n",
    "model = MillerIndexer(in_channels=in_channels, num_classes=num_classes)\n",
    "if not os.path.isfile(MODEL_PATH):\n",
    "    raise FileNotFoundError(f\"错误: 模型文件未找到 at '{MODEL_PATH}'\")\n",
    "\n",
    "ckpt = torch.load(MODEL_PATH, map_location='cpu', weights_only=False)\n",
    "try:\n",
    "    # 尝试加载可能存在的不同键名\n",
    "    if 'model_state_dict' in ckpt:\n",
    "        model.load_state_dict(ckpt['model_state_dict'])\n",
    "    elif 'model' in ckpt:\n",
    "        model.load_state_dict(ckpt['model'])\n",
    "    else:\n",
    "        model.load_state_dict(ckpt)\n",
    "except Exception as e:\n",
    "    print(f\"--> 模型加载失败: {e}\")\n",
    "    print(\"--> 将尝试以非严格模式加载\")\n",
    "    model.load_state_dict(ckpt.get('model_state_dict', ckpt), strict=False)\n",
    "print(\"--> 模型加载成功。\")\n",
    "if not os.path.isfile(DATA_FILE):\n",
    "    raise FileNotFoundError(f\"错误: 数据文件未找到 at '{DATA_FILE}'\")\n",
    "with open(DATA_FILE, 'r') as f:\n",
    "    line = f.readline()\n",
    "    sample_data = json.loads(line)\n",
    "print(f\"--> 使用可视化遮蔽比例: {VIS_MASKING_RATIO}\")\n",
    "points_raw = torch.tensor(sample_data['input_sequence'], dtype=torch.float32)\n",
    "labels_raw = torch.tensor(sample_data['labels'], dtype=torch.long)\n",
    "if labels_raw.ndim == 3:\n",
    "    labels_raw = labels_raw[0]\n",
    "coords_only = points_raw[:, :3]  # (N, 3)\n",
    "is_abs = num_classes < 11\n",
    "miller_offset = 0 if is_abs else 5\n",
    "if is_abs:\n",
    "    hkl_features_unmasked = torch.abs(labels_raw).clone().float() / 5.0\n",
    "else:\n",
    "    hkl_features_unmasked = labels_raw.clone().float() / 5.0\n",
    "num_points = points_raw.shape[0]\n",
    "num_to_mask = int(num_points * VIS_MASKING_RATIO)\n",
    "perm = torch.randperm(num_points)\n",
    "masked_indices = perm[:num_to_mask] # 保存 masked_indices 以供后续使用\n",
    "hkl_features_masked = hkl_features_unmasked.clone()\n",
    "if num_to_mask > 0:\n",
    "    hkl_features_masked[masked_indices, :] = 0.0 # 将h,k,l特征置为0\n",
    "points_raw[:, 3] /= 10 # 强度归一化\n",
    "points_raw[:, 1:3] = (points_raw[:, 1:3] - 0.5) * 0.99 / torch.max(points_raw[:, 1:3]) + 0.5\n",
    "if in_channels == 4:\n",
    "    feats_with_hkl = points_raw\n",
    "else:   \n",
    "    feats_with_hkl = torch.cat([points_raw, hkl_features_masked], dim=1) # (N, 7)\n",
    "if is_abs:\n",
    "    labels_final = torch.abs(labels_raw)\n",
    "else:\n",
    "    labels_final = labels_raw + miller_offset\n",
    "offsets = torch.tensor([len(coords_only)], dtype=torch.long)\n",
    "original_labels_tensor = labels_final\n",
    "original_intensities = points_raw[:, 3] * 10 # 恢复原始强度\n",
    "print(\"--> 数据加载和预处理完成。\")\n",
    "print(f\"    坐标 shape: {coords_only.shape}\")\n",
    "print(f\"    特征 shape: {feats_with_hkl.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05645106",
   "metadata": {},
   "source": [
    "### 3. 使用 Hooks 执行前向传播并捕获所有数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b999cf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Cell 4]\n",
    "\n",
    "def run_and_capture_with_hooks(model, p, x, o, original_labels, original_intensities_data, masked_indices_data, is_abs_label):\n",
    "    \"\"\"\n",
    "    使用 PyTorch Hooks 执行完整的前向传播并捕获所有用于可视化的数据。\n",
    "    \"\"\"\n",
    "    captured_coords = {}\n",
    "    hooks = []\n",
    "\n",
    "    def make_hook(name):\n",
    "        def hook(module, input, output):\n",
    "            captured_coords[name] = output.coord.cpu().numpy()\n",
    "        return hook\n",
    "\n",
    "    with torch.no_grad():\n",
    "        modules_to_hook = OrderedDict([\n",
    "            ('p0_embedding', model.backbone.embedding),\n",
    "            ('p1_enc', model.backbone.enc.enc0),\n",
    "            ('p2_enc', model.backbone.enc.enc1),\n",
    "            ('p3_enc', model.backbone.enc.enc2),\n",
    "            ('p4_enc', model.backbone.enc.enc3),\n",
    "            ('p5_enc', model.backbone.enc.enc4),\n",
    "            ('p4_dec', model.backbone.dec.dec3),\n",
    "            ('p3_dec', model.backbone.dec.dec2),\n",
    "            ('p2_dec', model.backbone.dec.dec1),\n",
    "            ('p1_dec', model.backbone.dec.dec0),\n",
    "        ])\n",
    "        \n",
    "        for name, module in modules_to_hook.items():\n",
    "            hooks.append(module.register_forward_hook(make_hook(name)))\n",
    "        \n",
    "        predictions_dict = model(p, x, o)\n",
    "        \n",
    "        for h in hooks:\n",
    "            h.remove()\n",
    "            \n",
    "        vis_data = {}\n",
    "        vis_data.update(captured_coords)\n",
    "        vis_data['p0_original'] = p.cpu().numpy()\n",
    "        \n",
    "        pred_h = torch.argmax(predictions_dict['h'], dim=1)\n",
    "        pred_k = torch.argmax(predictions_dict['k'], dim=1)\n",
    "        pred_l = torch.argmax(predictions_dict['l'], dim=1)\n",
    "        predictions = torch.stack([pred_h, pred_k, pred_l], dim=1)\n",
    "        \n",
    "        miller_offset_val = 0 if is_abs_label else 5\n",
    "        # 注意：这里的 'labels' 是未经处理的原始真实值 (例如 h in [-5, 5])\n",
    "        vis_data['predictions'] = (predictions.cpu().numpy() - miller_offset_val)\n",
    "        vis_data['labels'] = (original_labels.cpu().numpy() - miller_offset_val)\n",
    "        vis_data['intensities'] = original_intensities_data.cpu().numpy()\n",
    "        vis_data['masked_indices'] = masked_indices_data.cpu().numpy()\n",
    "        \n",
    "    return vis_data\n",
    "\n",
    "print(\"--> 正在使用 Hooks 执行完整前向传播以捕获所有数据...\")\n",
    "model.to('cuda')\n",
    "coords_only_gpu = coords_only.to('cuda')\n",
    "feats_with_hkl_gpu = feats_with_hkl.to('cuda') \n",
    "offsets_gpu = offsets.to('cuda')\n",
    "original_labels_tensor_gpu = original_labels_tensor.to('cuda')\n",
    "original_intensities_gpu = original_intensities.to('cuda')\n",
    "# 注意：masked_indices不需要上GPU，因为它只用于索引\n",
    "masked_indices_cpu = masked_indices\n",
    "\n",
    "vis_data = run_and_capture_with_hooks(\n",
    "    model, \n",
    "    coords_only_gpu, \n",
    "    feats_with_hkl_gpu, \n",
    "    offsets_gpu, \n",
    "    original_labels_tensor_gpu, \n",
    "    original_intensities_gpu,\n",
    "    masked_indices_cpu, # 传递masked_indices\n",
    "    is_abs_label=is_abs\n",
    ")\n",
    "print(\"--> 数据捕获完成。\")\n",
    "\n",
    "# --- 新增：计算并汇报精度指标 ---\n",
    "print(\"\\n--- 精度指标汇报 (仅计算被遮蔽的点) ---\")\n",
    "masked_preds = vis_data['predictions'][vis_data['masked_indices']]\n",
    "masked_labels = vis_data['labels'][vis_data['masked_indices']]\n",
    "num_masked_points = len(masked_labels)\n",
    "\n",
    "if num_masked_points > 0:\n",
    "    h_correct = (masked_preds[:, 0] == masked_labels[:, 0]).sum()\n",
    "    k_correct = (masked_preds[:, 1] == masked_labels[:, 1]).sum()\n",
    "    l_correct = (masked_preds[:, 2] == masked_labels[:, 2]).sum()\n",
    "    all_correct = ((masked_preds == masked_labels).all(axis=1)).sum()\n",
    "\n",
    "    print(f\"被遮蔽点数量: {num_masked_points}\")\n",
    "    print(f\"H  轴准确率: {h_correct / num_masked_points * 100:.2f}%\")\n",
    "    print(f\"K  轴准确率: {k_correct / num_masked_points * 100:.2f}%\")\n",
    "    print(f\"L  轴准确率: {l_correct / num_masked_points * 100:.2f}%\")\n",
    "    print(f\"HKL完全匹配准确率: {all_correct / num_masked_points * 100:.2f}%\")\n",
    "else:\n",
    "    print(\"没有被遮蔽的点，无法计算精度。\")\n",
    "print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15af45ec",
   "metadata": {},
   "source": [
    "### 4. 创建交互式3D可视化图表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283d13eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Cell 5]\n",
    "\n",
    "# --- 图 1：主交互式可视化图表 ---\n",
    "\n",
    "# 定义映射函数\n",
    "def hkl_to_rgb(hkl_array, is_abs=False):\n",
    "    hkl_array = np.abs(hkl_array) if is_abs else hkl_array\n",
    "    max_val = 5.0\n",
    "    # offset = 0 if is_abs else 5\n",
    "    offset = np.min(hkl_array) * -1\n",
    "    normalized = (hkl_array + offset) / (max_val + offset + 1e-6)\n",
    "    rgb_array = (np.clip(normalized, 0, 1) * 255).astype(int)\n",
    "    return [f'rgb({r},{g},{b})' for r, g, b in rgb_array]\n",
    "\n",
    "def intensity_to_size(intensities):\n",
    "    min_val, max_val = intensities.min(), intensities.max()\n",
    "    if max_val == min_val: return np.full_like(intensities, 4)\n",
    "    normalized = (intensities - min_val) / (max_val - min_val)\n",
    "    return 0 + (normalized + 0.5) ** 3\n",
    "\n",
    "STAGES = {\n",
    "    'gt_color': {'name': '真实标签 (颜色)', 'type': 'color'},\n",
    "    'pred_color': {'name': '模型预测 (颜色)', 'type': 'color'},\n",
    "    'gt_flow': {'name': '真实标签 (方向)', 'type': 'flow'},\n",
    "    'pred_flow': {'name': '模型预测 (方向)', 'type': 'flow'},\n",
    "    'p0_original': {'name': '原始点云', 'type': 'structure', 'color': 'royalblue'},\n",
    "    'p0_embedding': {'name': 'Embedding Out', 'type': 'structure', 'color': 'cyan'},\n",
    "    'p1_enc': {'name': 'Encoder 1', 'type': 'structure', 'color': 'darkorange'},\n",
    "    'p2_enc': {'name': 'Encoder 2', 'type': 'structure', 'color': 'green'},\n",
    "    'p3_enc': {'name': 'Encoder 3', 'type': 'structure', 'color': 'firebrick'},\n",
    "    'p4_enc': {'name': 'Encoder 4', 'type': 'structure', 'color': 'purple'},\n",
    "    'p5_enc': {'name': 'Encoder 5 (Bottleneck)', 'type': 'structure', 'color': 'saddlebrown'},\n",
    "    'p4_dec': {'name': 'Decoder 4', 'type': 'structure', 'color': 'mediumpurple'},\n",
    "    'p3_dec': {'name': 'Decoder 3', 'type': 'structure', 'color': 'lightcoral'},\n",
    "    'p2_dec': {'name': 'Decoder 2', 'type': 'structure', 'color': 'lightgreen'},\n",
    "    'p1_dec': {'name': 'Decoder 1 (Final)', 'type': 'structure', 'color': 'sandybrown'},\n",
    "}\n",
    "traces = []\n",
    "for key, stage_info in STAGES.items():\n",
    "    visible = (key == 'gt_color')\n",
    "    if stage_info['type'] == 'color':\n",
    "        hkl_data = vis_data['labels'] if 'gt' in key else vis_data['predictions']\n",
    "        points = vis_data['p0_original']\n",
    "        intns = vis_data['intensities'] # 修复：直接使用强度数据\n",
    "        traces.append(go.Scatter3d(\n",
    "            x=points[:, 0], y=points[:, 1], z=points[:, 2], mode='markers',\n",
    "            marker=dict(size=intensity_to_size(intns), color=hkl_to_rgb(hkl_data, is_abs=is_abs), opacity=0.9, line=dict(width=0)),\n",
    "            name=stage_info['name'],\n",
    "            customdata=np.hstack((hkl_data, intns[:, np.newaxis])),\n",
    "            hovertemplate='<b>hkl:</b> (%{customdata[0]}, %{customdata[1]}, %{customdata[2]})<br><b>强度:</b> %{customdata[3]:.2f}<br><b>坐标:</b> (%{x:.3f}, %{y:.3f}, %{z:.3f})<extra></extra>',\n",
    "            visible=visible\n",
    "        ))\n",
    "    elif stage_info['type'] == 'flow':\n",
    "        hkl_data = vis_data['labels'] if 'gt' in key else vis_data['predictions']\n",
    "        points = vis_data['p0_original']\n",
    "        intensities = vis_data['intensities'] # 修复：直接使用强度数据\n",
    "        hkl_vectors = hkl_data.astype(np.float32)\n",
    "        norms = np.linalg.norm(hkl_vectors, axis=1)\n",
    "        non_zero_mask = norms > 1e-6\n",
    "        zero_points = points[~non_zero_mask]\n",
    "        traces.append(go.Scatter3d(x=zero_points[:,0], y=zero_points[:,1], z=zero_points[:,2], mode='markers', marker=dict(color='grey', size=2, opacity=0.6), hoverinfo='skip', visible=visible, name=f\"{stage_info['name']} (zero hkl)\"))\n",
    "        if np.any(non_zero_mask):\n",
    "            start_points = points[non_zero_mask]\n",
    "            directions = hkl_vectors[non_zero_mask] / norms[non_zero_mask, np.newaxis]\n",
    "            intensities_nz = intensities[non_zero_mask]\n",
    "            lengths = 0.00 + 0.1 * (intensities_nz - intensities_nz.min()) / (intensities_nz.max() - intensities_nz.min() + 1e-6)\n",
    "            end_points = start_points + directions * lengths[:, np.newaxis]\n",
    "            lines_x, lines_y, lines_z = [], [], []\n",
    "            for i in range(len(start_points)):\n",
    "                lines_x.extend([start_points[i,0], end_points[i,0], None]); lines_y.extend([start_points[i,1], end_points[i,1], None]); lines_z.extend([start_points[i,2], end_points[i,2], None])\n",
    "            intensities_repeat = np.repeat(intensities_nz, 3)\n",
    "            traces.append(go.Scatter3d(x=lines_x, y=lines_y, z=lines_z, mode='lines', line=dict(width=0.4, color=intensities_repeat, colorscale='Bluered', cmin=intensities_nz.min(), cmax=intensities_nz.max()), customdata=intensities_repeat, hovertemplate='<b>强度:</b> %{customdata:.2f}<extra></extra>', visible=visible, name=f\"{stage_info['name']} (vectors)\"))\n",
    "        else:\n",
    "            traces.append(go.Scatter3d(x=[],y=[],z=[], visible=visible))\n",
    "    elif stage_info['type'] == 'structure':\n",
    "        if key in vis_data:\n",
    "            points = vis_data[key]\n",
    "            traces.append(go.Scatter3d(x=points[:, 0] * 2, y=points[:, 1], z=points[:, 2], mode='markers', marker=dict(size=1, color=stage_info['color'], opacity=0.8), name=f\"{stage_info['name']} ({len(points)} points)\", visible=visible))\n",
    "        else:\n",
    "            print(f\"警告: 在vis_data中未找到键 '{key}'，跳过此阶段。\"); traces.append(go.Scatter3d(x=[], y=[], z=[], visible=visible))\n",
    "\n",
    "fig = go.Figure(data=traces)\n",
    "buttons = []\n",
    "trace_counter = 0\n",
    "for key, stage_info in STAGES.items():\n",
    "    visibility = [False] * len(traces)\n",
    "    num_traces = 2 if stage_info['type'] == 'flow' else 1\n",
    "    for i in range(num_traces):\n",
    "        if trace_counter + i < len(traces): visibility[trace_counter + i] = True\n",
    "    trace_counter += num_traces\n",
    "    buttons.append(dict(label=stage_info['name'], method='update', args=[{'visible': visibility}, {'title': f\"当前可视化: {stage_info['name']}\"}]))\n",
    "fig.update_layout(\n",
    "    title_text=\"当前可视化: 真实标签 (颜色)\",\n",
    "    updatemenus=[dict(active=0, buttons=buttons, direction=\"down\", pad={\"r\": 10, \"t\": 10}, showactive=True, x=0.01, xanchor=\"left\", y=1.1, yanchor=\"top\")],\n",
    "    scene=dict(\n",
    "        xaxis=dict(showgrid=False, zeroline=False, showticklabels=False, showspikes=False, showbackground=False, ticks=''),\n",
    "        yaxis=dict(showgrid=False, zeroline=False, showticklabels=False, showspikes=False, showbackground=False, ticks=''),\n",
    "        zaxis=dict(showgrid=False, zeroline=False, showticklabels=False, showspikes=False, showbackground=False, ticks=''),\n",
    "        aspectmode='data'\n",
    "    ),\n",
    "    margin=dict(l=0, r=0, b=0, t=40),\n",
    "    legend=dict(orientation=\"h\", yanchor=\"bottom\", y=0.01, xanchor=\"right\", x=1)\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "\n",
    "# --- 新增 图 2：可视化 Mask 点云分布 ---\n",
    "all_points = vis_data['p0_original']\n",
    "masked_indices = vis_data['masked_indices']\n",
    "unmasked_indices = np.setdiff1d(np.arange(len(all_points)), masked_indices)\n",
    "masked_points = all_points[masked_indices]\n",
    "unmasked_points = all_points[unmasked_indices]\n",
    "print(len(unmasked_points), len(masked_points))\n",
    "\n",
    "fig_mask = go.Figure()\n",
    "# 未被遮蔽的点\n",
    "fig_mask.add_trace(go.Scatter3d(\n",
    "    x=unmasked_points[:, 0], y=unmasked_points[:, 1], z=unmasked_points[:, 2],\n",
    "    mode='markers',\n",
    "    marker=dict(size=1, color='black', opacity=1),\n",
    "    name=f'Unmasked Points ({len(unmasked_points)})'\n",
    "))\n",
    "# 被遮蔽的点\n",
    "fig_mask.add_trace(go.Scatter3d(\n",
    "    x=masked_points[:, 0], y=masked_points[:, 1], z=masked_points[:, 2],\n",
    "    mode='markers',\n",
    "    marker=dict(size=0.3, color='white'),\n",
    "    name=f'Masked Points ({len(masked_points)})'\n",
    "))\n",
    "fig_mask.update_layout(\n",
    "    title='可视化：被遮蔽点(Masked)的分布',\n",
    "    scene=dict(\n",
    "        xaxis=dict(showgrid=False, zeroline=False, showticklabels=False, showspikes=False, showbackground=False, ticks=''),\n",
    "        yaxis=dict(showgrid=False, zeroline=False, showticklabels=False, showspikes=False, showbackground=False, ticks=''),\n",
    "        zaxis=dict(showgrid=False, zeroline=False, showticklabels=False, showspikes=False, showbackground=False, ticks=''),\n",
    "        aspectmode='data'\n",
    "    ),\n",
    "    margin=dict(l=0, r=0, b=0, t=40)\n",
    ")\n",
    "fig_mask.show()\n",
    "\n",
    "\n",
    "# --- 新增 图 3：可视化 Label 与 Output 的 hkl 差异 ---\n",
    "preds = vis_data['predictions']\n",
    "labels = vis_data['labels']\n",
    "points = vis_data['p0_original']\n",
    "\n",
    "# 计算 L2 差异\n",
    "l2_diff = np.sum(np.abs(preds - labels), axis=1) * -1\n",
    "\n",
    "fig_diff = go.Figure()\n",
    "fig_diff.add_trace(go.Scatter3d(\n",
    "    x=points[:, 0], y=points[:, 1], z=points[:, 2],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=1,\n",
    "        color=l2_diff, # 使用差异作为颜色\n",
    "        colorscale='Reds_r',\n",
    "        cmin=0,\n",
    "        cmax=l2_diff.max(), # 避免除以0\n",
    "        colorbar=dict(title=\"HKL L2 差异\"), \n",
    "        line=dict(width=0)\n",
    "    ),\n",
    "    customdata=np.hstack((preds, labels, l2_diff[:, np.newaxis])),\n",
    "    hovertemplate=(\n",
    "        '<b>Pred:</b> (%{customdata[0]}, %{customdata[1]}, %{customdata[2]})<br>'\n",
    "        '<b>Label:</b> (%{customdata[3]}, %{customdata[4]}, %{customdata[5]})<br>'\n",
    "        '<b>L2 Diff:</b> %{customdata[6]:.2f}<br>'\n",
    "        '<b>Coord:</b> (%{x:.3f}, %{y:.3f}, %{z:.3f})<extra></extra>'\n",
    "    ),\n",
    "    name='HKL Difference'\n",
    "))\n",
    "fig_diff.update_layout(\n",
    "    title='可视化：预测与真实标签的 hkl 差异 (L2距离)',\n",
    "    scene=dict(\n",
    "        xaxis=dict(showgrid=False, zeroline=False, showticklabels=False, showspikes=False, showbackground=False, ticks=''),\n",
    "        yaxis=dict(showgrid=False, zeroline=False, showticklabels=False, showspikes=False, showbackground=False, ticks=''),\n",
    "        zaxis=dict(showgrid=False, zeroline=False, showticklabels=False, showspikes=False, showbackground=False, ticks=''),\n",
    "        aspectmode='data'\n",
    "    ),\n",
    "    margin=dict(l=0, r=0, b=0, t=40)\n",
    ")\n",
    "fig_diff.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cp312_cu128",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
